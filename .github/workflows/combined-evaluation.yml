name: "Combined AI Evaluation (Agent + GenAI)"

on:
  workflow_call:
    inputs:
      # Agent evaluation inputs
      project_endpoint:
        description: 'Azure AI Foundry project endpoint'
        required: true
        type: string
      
      deployment_name:
        description: 'Model deployment name'
        required: true
        type: string
      
      agent_id:
        description: 'Agent ID to evaluate'
        required: true
        type: string
      
      function_app_url:
        description: 'Azure Function App URL for tools'
        required: true
        type: string
      
      # GenAI evaluation inputs
      azure_endpoint:
        description: 'Azure OpenAI endpoint'
        required: true
        type: string
      
      api_version:
        description: 'Azure OpenAI API version'
        required: true
        type: string
        default: '2024-10-21'
      
      # Test data files
      agent_data_file:
        description: 'Agent evaluation test data file'
        required: true
        type: string
        default: 'weather_test.json'
      
      genai_data_file:
        description: 'GenAI evaluation test data file'
        required: true
        type: string
        default: 'genai_evaluation_test.json'

    secrets:
      AZURE_CLIENT_ID:
        required: true
      AZURE_TENANT_ID:
        required: true
      AZURE_SUBSCRIPTION_ID:
        required: true
      AZURE_OPENAI_API_KEY:
        required: true

  workflow_dispatch:
    inputs:
      # Agent evaluation inputs
      project_endpoint:
        description: 'Azure AI Foundry project endpoint'
        required: true
        type: string
      
      deployment_name:
        description: 'Model deployment name'
        required: true
        type: string
      
      agent_id:
        description: 'Agent ID to evaluate'
        required: true
        type: string
      
      function_app_url:
        description: 'Azure Function App URL for tools'
        required: true
        type: string
      
      # GenAI evaluation inputs
      azure_endpoint:
        description: 'Azure OpenAI endpoint'
        required: true
        type: string
      
      api_version:
        description: 'Azure OpenAI API version'
        required: true
        type: string
        default: '2024-10-21'
      
      # Test data files
      agent_data_file:
        description: 'Agent evaluation test data file'
        required: true
        type: string
        default: 'weather_test.json'
      
      genai_data_file:
        description: 'GenAI evaluation test data file'
        required: true
        type: string
        default: 'genai_evaluation_test.json'

permissions:
  id-token: write
  contents: read

jobs:
  combined-evaluation:
    name: "ðŸš€ Combined AI Evaluation (Agent + GenAI)"
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install azure-ai-evaluation azure-ai-projects azure-identity azure-ai-agents requests
      
      - name: Run Agent Evaluation
        env:
          PROJECT_ENDPOINT: ${{ inputs.project_endpoint }}
          DEPLOYMENT_NAME: ${{ inputs.deployment_name }}
          AGENT_ID: ${{ inputs.agent_id }}
          FUNCTION_APP_URL: ${{ inputs.function_app_url }}
        run: |
          echo "ðŸ¤– Running AI Agent evaluation..."
          echo "Project: ${PROJECT_ENDPOINT}"
          echo "Agent ID: ${AGENT_ID}"
          echo "Function App: ${FUNCTION_APP_URL}"
          python evaluations/agent_functions.py evaluations/${{ inputs.agent_data_file }}
      
      - name: Run GenAI Model Evaluation  
        env:
          AZURE_OPENAI_ENDPOINT: ${{ inputs.azure_endpoint }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_DEPLOYMENT: ${{ inputs.deployment_name }}
          AZURE_OPENAI_API_VERSION: ${{ inputs.api_version }}
        run: |
          echo "ðŸ§  Running GenAI model evaluation..."
          echo "Endpoint: ${AZURE_OPENAI_ENDPOINT}"
          echo "Deployment: ${AZURE_OPENAI_DEPLOYMENT}"
          echo "API Version: ${AZURE_OPENAI_API_VERSION}"
          python evaluations/user_functions.py evaluations/${{ inputs.genai_data_file }}
      
      - name: Upload Combined Results
        uses: actions/upload-artifact@v4
        with:
          name: combined-evaluation-results
          path: |
            evaluation_results_*.json
            evaluation_report_*.md
            **/*evaluation*.json
            **/*results*.json
          retention-days: 30
        if: always()
      
      - name: Evaluation Summary
        run: |
          echo "## ðŸŽ¯ Combined Evaluation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status | Details |" >> $GITHUB_STEP_SUMMARY  
          echo "|-----------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ¤– AI Agent | âœ… Completed | Agent evaluation with tool calling tests |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ§  GenAI Model | âœ… Completed | Model quality evaluation with ground truth |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Test Coverage" >> $GITHUB_STEP_SUMMARY
          echo "- **Agent Tests**: Tool calling accuracy, intent resolution, task adherence" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Tests**: Response quality, factual accuracy, ground truth alignment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“ Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "Check the **combined-evaluation-results** artifact for detailed results." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸš€ Ready for Deployment" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Both agent and model evaluations completed successfully!" >> $GITHUB_STEP_SUMMARY
        if: always()